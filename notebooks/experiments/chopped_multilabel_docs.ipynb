{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some samples contain more than one document. This notebook explores the idea of having a separate model for 1) multi-page samples and 2) samples without page-breaks.\n",
    "\n",
    "A sample without page-breaks is guaranteed to be single document => model 2\n",
    "A sample with page-breaks may be broken into individual pages. Each is potentially a separate document => model 1\n",
    "\n",
    "We plan to test 3 separate models.\n",
    "- One is trained on data without page-breaks (model 1)\n",
    "- One is trained on data with page-breaks (candidate for model 2)\n",
    "- One is trained on data without page-breaks, but page-breaks are introduced artificially (candidate for model 2)\n",
    "\n",
    "\n",
    "PROBLEM: both pagebreaks and no_pagebreaks datasets are labelled with a single label but are potentially multilabel. Thus, there are no training for multilabel cases.\n",
    "We can merely get the chopped dataset and manually inspect the results of a model trained on it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overview:\n",
    "- prepare dataset without page-breaks\n",
    "- prepare dataset with page-breaks\n",
    "- check for overlap of the two datasets (using ID). If there is an overlap, remove the overlap from the dataset without page-breaks (which is much larger and hence we can afford to make it smaller for the benefit of the smaller dataset)\n",
    "\n",
    "- train model 1 (dataset without page-breaks)\n",
    "- train model 2 (dataset with page-breaks)\n",
    "\n",
    "- try chopping the dataset without page-breaks to produce an artificial dataset with page-breaks. Try different chopping approaches\n",
    "- train model 3 on the chopped dataset\n",
    "- compare model 3 and model 2 and pick one/combine them\n",
    "\n",
    "- create a wrapper that will decide which model to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mltools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset without page-breaks\n",
    "df_no_pagebreaks = pd.read_parquet('/Users/ondrejgutten/Work/PISI.nosync/data/PB/SpisyPB18-PB24_v2.parquet')\n",
    "df_no_pagebreaks = df_no_pagebreaks[df_no_pagebreaks.iloc[:,3].str.isupper() == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset with page-breaks\n",
    "df_pagebreaks = pd.read_parquet('/Users/ondrejgutten/Work/PISI.nosync/data/PB/Spisy2024-12-03-14-24_PB18-PB24_zlomyStran_remapped.parquet')\n",
    "# check if column 3 is all caps\n",
    "df_pagebreaks = df_pagebreaks[df_pagebreaks[3].str.isupper() == True]\n",
    "df_pagebreaks = df_pagebreaks[df_pagebreaks[4].apply(lambda x: 'zlom' in x)]\n",
    "\n",
    "X_pagebreaks = df_pagebreaks.iloc[:,4]\n",
    "y_pagebreaks = df_pagebreaks.iloc[:,3]\n",
    "\n",
    "X_train_pagebreaks, X_test_pagebreaks, y_train_pagebreaks, y_test_pagebreaks = train_test_split(X_pagebreaks, y_pagebreaks, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for overlap of datasets with and without page-breaks\n",
    "debt_ids_no_pagebreaks = df_no_pagebreaks.iloc[:,0].unique().astype(str)\n",
    "debt_ids_pagebreaks = df_pagebreaks.iloc[:,0].unique().astype(str)\n",
    "debt_ids_intersection = np.intersect1d(debt_ids_no_pagebreaks, debt_ids_pagebreaks)\n",
    "\n",
    "df_no_pagebreaks_minus_intersection = df_no_pagebreaks[~df_no_pagebreaks.iloc[:,0].astype(str).isin(debt_ids_intersection)] \n",
    "\n",
    "X_no_pagebreaks = df_no_pagebreaks_minus_intersection.iloc[:,4]\n",
    "y_no_pagebreaks = df_no_pagebreaks_minus_intersection.iloc[:,3]\n",
    "\n",
    "X_train_no_pagebreaks, X_test_no_pagebreaks, y_train_no_pagebreaks, y_test_no_pagebreaks = train_test_split(X_no_pagebreaks, y_no_pagebreaks, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model on dataset without page-breaks\n",
    "xgb_pagebreaks = mltools.architecture.TF_IDF_XGBoost('pagebreaks',{})\n",
    "xgb_pagebreaks.fit(X_train_pagebreaks, y_train_pagebreaks)\n",
    "xgb_pagebreaks_predictions = xgb_pagebreaks.predict(X_test_pagebreaks)\n",
    "print(accuracy_score(y_test_pagebreaks, xgb_pagebreaks_predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model on dataset without page-breaks\n",
    "xgb_no_pagebreaks = mltools.architecture.TF_IDF_XGBoost('no_pagebreaks',{})\n",
    "xgb_no_pagebreaks.fit(X_train_no_pagebreaks, y_train_no_pagebreaks)\n",
    "xgb_no_pagebreaks_predictions = xgb_no_pagebreaks.predict(X_test_no_pagebreaks)\n",
    "print(accuracy_score(y_test_no_pagebreaks, xgb_no_pagebreaks_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chop dataset without page-breaks into artificial pages\n",
    "def chop_data(X, y, length):\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    X_chopped = []\n",
    "    y_chopped = []\n",
    "    for i in range(len(X)):\n",
    "        for j in range(0, len(X[i]), length):\n",
    "            X_chopped.append(X[i][j:j+length])\n",
    "            y_chopped.append(y[i])\n",
    "\n",
    "    return X_chopped, y_chopped\n",
    "\n",
    "X_train_chopped, y_train_chopped = chop_data(X_train_no_pagebreaks, y_train_no_pagebreaks, 1000)\n",
    "X_test_chopped, y_test_chopped = chop_data(X_test_no_pagebreaks, y_test_no_pagebreaks, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train model on the chopped dataset\n",
    "xgb_chopped = mltools.architecture.TF_IDF_XGBoost('chopped',{})\n",
    "xgb_chopped.fit(X_train_chopped, y_train_chopped)\n",
    "xgb_chopped_predictions = xgb_chopped.predict(X_test_chopped)\n",
    "print(accuracy_score(y_test_chopped, xgb_chopped_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare model trained on dataset with page-breaks and the model trained on the chopped dataset. Pick/combine a final model for page-break samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrap both models into a single model with a page-break detection mechanism"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
